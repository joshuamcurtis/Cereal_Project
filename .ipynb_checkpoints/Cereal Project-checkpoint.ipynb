{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7340f86b",
   "metadata": {},
   "source": [
    "# Econ 1923 - Product Differentiation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0697a",
   "metadata": {},
   "source": [
    "## 1 Preparation\n",
    "### 1.1 Obtaining the data\n",
    "Create a data set containing nutrition information about cereal boxes. You can use all sources including the nutrition APIs, stores web pages, actual grocery stores, your pantry, etc.\n",
    "At the end of this process, you should have a dataframe that contains as many cereal boxes as possible and for each, you should have several nutritional facts and (ideally) serving sizes (cups or grams).\n",
    "The result of this part can be several dataframes, each resulting from the different data sources that you used.\n",
    "\n",
    "Sources: Edemam API, GitHub JSON Files, personal cereals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7787a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import requests, json, time\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%run ../APIkeys.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d73129",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = os.environ['EDAMAM_API_id']\n",
    "key = os.environ['EDAMAM_API_key']\n",
    "baseURL = 'https://api.edamam.com/api/food-database/v2/parser?app_id='+app_id+'&app_key='+key+'&upc='\n",
    "endURL = '&nutrition-type=cooking&category=packaged-foods'\n",
    "\n",
    "pd.set_option('display.max_rows', None, 'display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edfd1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkUPC_V2(upc):\n",
    "    app_id = os.environ['EDAMAM_API_id']\n",
    "    key = os.environ['EDAMAM_API_key']\n",
    "    baseURL = 'https://api.edamam.com/api/food-database/v2/parser?app_id='+app_id+'&app_key='+key+'&upc='\n",
    "    endURL = '&nutrition-type=cooking&category=packaged-foods'\n",
    "    url = baseURL + upc + endURL\n",
    "    info = requests.get(url).json()\n",
    "    if 'error' in info:\n",
    "        return info\n",
    "    else:\n",
    "        answer = info['hints'][0]['food']['nutrients']\n",
    "        \n",
    "        sizeList = info['hints'][0]['food']['servingSizes']\n",
    "        n = len(sizeList)\n",
    "        for i in range(n):\n",
    "            if sizeList[i]['label'] == 'Gram':\n",
    "                answer['servingSize_gram'] = info['hints'][0]['food']['servingSizes'][i]['quantity']\n",
    "            if sizeList[i]['label'] == 'Cup':\n",
    "                answer['servingSize_cup'] = info['hints'][0]['food']['servingSizes'][i]['quantity']\n",
    "        \n",
    "        answer['label'] = info['hints'][0]['food']['label']\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d223ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add a 3 second interval between each call to stay under the limit for the Edamam API.\n",
    "\n",
    "def multiUPC(shelf):\n",
    "    a = []\n",
    "    missing = []\n",
    "    for upc in shelf:\n",
    "        info = checkUPC_V2(upc)\n",
    "        if 'error' in info:\n",
    "            print('UPC ',upc, ' does not exist in the API\\'s data base')\n",
    "            missing.append(upc)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            print('UPC ',upc, ' exists in the API\\'s data base')\n",
    "            a.append(info)\n",
    "            time.sleep(3)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd031000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading excel and csv files containing states' WIC \n",
    "#Approved Products Lists (APLs) and filtering down to cereal UPCs\n",
    "\n",
    "df_IL = pd.read_excel('IL_WIC_APL.xlsx') #Illinois\n",
    "df_IL = df_IL.drop([174], axis=0)\n",
    "df_IL = df_IL.reset_index(drop=True)\n",
    "\n",
    "df_MA = pd.read_excel('MA_WIC_APL.xlsx')\n",
    "df_MA = df_MA[df_MA['Category Name']=='Breakfast Cereal'] #Massachusetts\n",
    "df_MA = df_MA.reset_index(drop=True)\n",
    "\n",
    "df_MN = pd.read_excel('MN_WIC_APL.xlsx')#Minnesota\n",
    "\n",
    "df_NE = pd.read_excel('NE_WIC_APL.xlsx')#Nebraska\n",
    "\n",
    "df_NV = pd.read_csv('NV_WIC_APL.csv')#Nevada\n",
    "\n",
    "df_NY = pd.read_excel('NY_WIC_APL.xlsx')#New York S\n",
    "df_NY = df_NY[df_NY['Category']=='Breakfast Cereal ']\n",
    "df_NY = df_NY.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062eda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolating UPCs into string arrays and combining\n",
    "IL_UPCs = []\n",
    "for i in range(0,len(df_IL['UPC/PLU Code'])-1):\n",
    "    IL_UPCs.append(df_IL['UPC/PLU Code'][i][7:18])\n",
    "    \n",
    "MA_UPCs = []\n",
    "for i in range(0,len(df_MA['UPC'])-1):\n",
    "    MA_UPCs.append(str(df_MA['UPC'][i]))\n",
    "\n",
    "MN_UPCs = []\n",
    "for i in range(0,len(df_MN['UPC_PLU'])-1):\n",
    "    MN_UPCs.append(str(df_MN['UPC_PLU'][i]))\n",
    "    \n",
    "NE_UPCs = []\n",
    "for i in range(0,len(df_NE['UPC'])-1):\n",
    "    NE_UPCs.append(str(df_NE['UPC'][i]))\n",
    "\n",
    "NV_UPCs = []\n",
    "for i in range(0,len(df_NV['UPC'])-1):\n",
    "    if len(df_NV['UPC'][i])==14:\n",
    "        NV_UPCs.append(df_NV['UPC'][i][2:13])\n",
    "    elif len(df_NV['UPC'][i])==15:\n",
    "        NV_UPCs.append(df_NV['UPC'][i][3:14])\n",
    "\n",
    "NY_UPCs = []\n",
    "for i in range(0,len(df_NY['UPC/PLU Number'])-1):\n",
    "    if len(str(df_NY['UPC/PLU Number'][i]))==11:\n",
    "        NY_UPCs.append(str(df_NY['UPC/PLU Number'][i]))\n",
    "    elif len(str(df_NY['UPC/PLU Number'][i]))==12:\n",
    "        NY_UPCs.append(str(df_NY['UPC/PLU Number'][i])[1:12])\n",
    "        \n",
    "UPCs = IL_UPCs + MA_UPCs + MN_UPCs + NE_UPCs + NV_UPCs + NY_UPCs #combining\n",
    "UPCs = list(set(UPCs)) #removes duplicate UPCs, and then coerces into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28470646",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, missing = multiUPC(UPCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d0b21",
   "metadata": {},
   "source": [
    "####### This is is for if the above function doesn't work, for some reason it is buggy when running large batches, but running it manually without the funtion works for some reason\n",
    "\n",
    "####### Change this block to Code to run\n",
    "\n",
    "boxes = []\n",
    "missing = []\n",
    "for upc in UPCs:\n",
    "    info = checkUPC_V2(upc)\n",
    "    if 'error' in info:\n",
    "        print('UPC ',upc, ' does not exist in the API\\'s data base')\n",
    "        missing.append(upc)\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print('UPC ',upc, ' exists in the API\\'s data base')\n",
    "        boxes.append(info)\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fee8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cereals = pd.DataFrame(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fea9bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The dataframe appears to still have some duplicate cereal labels, so we're dropping them\n",
    "Cereals = Cereals.drop_duplicates(subset=['label'],keep='last')\n",
    "\n",
    "#Add source column and fill with \n",
    "Cereals['Source'] = 'EDAMAM_API'\n",
    "\n",
    "#Since calling all the UPCs takes a long time, we're saving the \n",
    "#dataframe into an excel sheet for quicker loader later on\n",
    "Cereals.to_excel(\"Cereals.xlsx\", sheet_name='Cereal Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ae2ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cereals = pd.read_excel('Cereals.xlsx')\n",
    "len(Cereals['label'])\n",
    "\n",
    "#Cereals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29abce5b",
   "metadata": {},
   "source": [
    "### 1.2 Cleaning and re-scaling\n",
    "Various data sources may contain different variable names, different units, or different serving sizes. Also, missing values can be an issue. Here, you are asked to:\n",
    "- Make sure that variable names in all dataframes that you created match.\n",
    "- Make sure that all nutritional measurements in all data frames are the same (e.g. per cup or per 100gr).\n",
    "- Merge the different data sources.\n",
    " \n",
    "The final data set should include a column indicating the source of the observation (i.e. is it from the API, entered manually from a certain store, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8ece8",
   "metadata": {},
   "source": [
    "### 1.3 Descriptive statistics\n",
    "Create a table with descriptive statistics (Mean, Median, standard deviation, range, number of missing observations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c2a14",
   "metadata": {},
   "source": [
    "## 2 Market Analysis\n",
    "### 2.1 Visualisation\n",
    "Create scatter plots of the data. Here you have to try several pairs of characteristics on which it seems like the products are more differentiated. This is a visual exercise but you can support your claims by looking at standard deviations and correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf3afc6",
   "metadata": {},
   "source": [
    "### 2.2 K-Means clustering\n",
    "Using the K-means clustering technique analyze the degree of product differentiation. Based on descriptive statistics, data availability, and scatter plots, choose pairs of features (i.e., nutrition facts) on which you believe the sellers differentiate themselves. Quantify your answer. You should try different K parameters. Report the goodness of fit (total sum of errors). *Instead of different pairs of features you can focus on the same pair and compare different locations or different supermarkets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ceb4f1",
   "metadata": {},
   "source": [
    "## 3 Conclusions\n",
    "Summarize your findings and draw conclusions from them. What can you recommend to cereal producers on the market? Do you find this market to be saturated? Here, I leave it to you to analyze your findings as you see fit. Given all the effort you have put, This section should be as very important."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
